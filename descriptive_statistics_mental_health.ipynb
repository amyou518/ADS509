{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78862705",
   "metadata": {},
   "source": [
    "## Descriptive Statistics\n",
    "\n",
    "### Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37227294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from collections import Counter\n",
    "from joblib import Parallel, delayed\n",
    "from gensim import corpora\n",
    "\n",
    "import string \n",
    "from string import punctuation\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import random\n",
    "\n",
    "import praw\n",
    "\n",
    "# supress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"wordcloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b314005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/samantharivas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/samantharivas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/samantharivas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/samantharivas/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecc4e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data \n",
    "df = pd.read_csv('data/reddit_posts.csv')\n",
    "mental_health_support_df = pd.read_csv('data/mental_health_support_posts.csv')\n",
    "mental_health_df = pd.read_csv('data/mental_health_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82873f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>media_only</th>\n",
       "      <th>permalink</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>downvotes</th>\n",
       "      <th>upvotes/subscribers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I feel hopeless.</td>\n",
       "      <td>157</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2024-03-01 11:35:07</td>\n",
       "      <td>Hi, I’m 24F. I stay home 24/7 , everyday. I do...</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>Odd-View-667</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/MentalHealthSupport/comments/1b3s6ad/i_feel...</td>\n",
       "      <td>154.0</td>\n",
       "      <td>158.585859</td>\n",
       "      <td>1.585859</td>\n",
       "      <td>0.003425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What changes your negative thoughts/ has made ...</td>\n",
       "      <td>45</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2024-03-03 05:40:38</td>\n",
       "      <td>I am learning that affirmations and the like c...</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>Bananasloog1998</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/MentalHealthSupport/comments/1b59lzz/what_c...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the point of living?</td>\n",
       "      <td>44</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2024-03-02 04:33:58</td>\n",
       "      <td>\\ncontent warning for suicide.\\n\\n\\n\\nI dont u...</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>penjamincranklin</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/MentalHealthSupport/comments/1b4fkko/what_i...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>47.311828</td>\n",
       "      <td>3.311828</td>\n",
       "      <td>0.001022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I need a hug</td>\n",
       "      <td>25</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2024-03-04 12:56:01</td>\n",
       "      <td>I wanna end me.</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>Positive-Parthlow</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/MentalHealthSupport/comments/1b6a8vz/i_need...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.315789</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>0.000568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are you like after a hug</td>\n",
       "      <td>21</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2024-03-06 15:18:23</td>\n",
       "      <td>If I hug someone I just try my best not to cry...</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>itsRileyigitbanned</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/MentalHealthSupport/comments/1b8299d/what_a...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.649485</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title score upvote_ratio  \\\n",
       "0                                   I feel hopeless.   157         0.99   \n",
       "1  What changes your negative thoughts/ has made ...    45         0.99   \n",
       "2                       what is the point of living?    44         0.93   \n",
       "3                                       I need a hug    25         0.95   \n",
       "4                      What are you like after a hug    21         0.97   \n",
       "\n",
       "           created_utc                                           selftext  \\\n",
       "0  2024-03-01 11:35:07  Hi, I’m 24F. I stay home 24/7 , everyday. I do...   \n",
       "1  2024-03-03 05:40:38  I am learning that affirmations and the like c...   \n",
       "2  2024-03-02 04:33:58  \\ncontent warning for suicide.\\n\\n\\n\\nI dont u...   \n",
       "3  2024-03-04 12:56:01                                    I wanna end me.   \n",
       "4  2024-03-06 15:18:23  If I hug someone I just try my best not to cry...   \n",
       "\n",
       "             subreddit              author media_only  \\\n",
       "0  MentalHealthSupport        Odd-View-667      False   \n",
       "1  MentalHealthSupport     Bananasloog1998      False   \n",
       "2  MentalHealthSupport    penjamincranklin      False   \n",
       "3  MentalHealthSupport   Positive-Parthlow      False   \n",
       "4  MentalHealthSupport  itsRileyigitbanned      False   \n",
       "\n",
       "                                           permalink  num_comments  \\\n",
       "0  /r/MentalHealthSupport/comments/1b3s6ad/i_feel...         154.0   \n",
       "1  /r/MentalHealthSupport/comments/1b59lzz/what_c...          21.0   \n",
       "2  /r/MentalHealthSupport/comments/1b4fkko/what_i...          24.0   \n",
       "3  /r/MentalHealthSupport/comments/1b6a8vz/i_need...          26.0   \n",
       "4  /r/MentalHealthSupport/comments/1b8299d/what_a...          17.0   \n",
       "\n",
       "      upvotes  downvotes  upvotes/subscribers  \n",
       "0  158.585859   1.585859             0.003425  \n",
       "1   45.454545   0.454545             0.000982  \n",
       "2   47.311828   3.311828             0.001022  \n",
       "3   26.315789   1.315789             0.000568  \n",
       "4   21.649485   0.649485             0.000468  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86aa64be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>media_only</th>\n",
       "      <th>permalink</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>downvotes</th>\n",
       "      <th>upvotes/subscribers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I feel hopeless.</td>\n",
       "      <td>157</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2024-03-01 11:35:07</td>\n",
       "      <td>Hi, I’m 24F. I stay home 24/7 , everyday. I do...</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>Odd-View-667</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/MentalHealthSupport/comments/1b3s6ad/i_feel...</td>\n",
       "      <td>154.0</td>\n",
       "      <td>158.585859</td>\n",
       "      <td>1.585859</td>\n",
       "      <td>0.003425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What changes your negative thoughts/ has made ...</td>\n",
       "      <td>45</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2024-03-03 05:40:38</td>\n",
       "      <td>I am learning that affirmations and the like c...</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>Bananasloog1998</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/MentalHealthSupport/comments/1b59lzz/what_c...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the point of living?</td>\n",
       "      <td>44</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2024-03-02 04:33:58</td>\n",
       "      <td>\\ncontent warning for suicide.\\n\\n\\n\\nI dont u...</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>penjamincranklin</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/MentalHealthSupport/comments/1b4fkko/what_i...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>47.311828</td>\n",
       "      <td>3.311828</td>\n",
       "      <td>0.001022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I need a hug</td>\n",
       "      <td>25</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2024-03-04 12:56:01</td>\n",
       "      <td>I wanna end me.</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>Positive-Parthlow</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/MentalHealthSupport/comments/1b6a8vz/i_need...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.315789</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>0.000568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are you like after a hug</td>\n",
       "      <td>21</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2024-03-06 15:18:23</td>\n",
       "      <td>If I hug someone I just try my best not to cry...</td>\n",
       "      <td>MentalHealthSupport</td>\n",
       "      <td>itsRileyigitbanned</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/MentalHealthSupport/comments/1b8299d/what_a...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.649485</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title score upvote_ratio  \\\n",
       "0                                   I feel hopeless.   157         0.99   \n",
       "1  What changes your negative thoughts/ has made ...    45         0.99   \n",
       "2                       what is the point of living?    44         0.93   \n",
       "3                                       I need a hug    25         0.95   \n",
       "4                      What are you like after a hug    21         0.97   \n",
       "\n",
       "           created_utc                                           selftext  \\\n",
       "0  2024-03-01 11:35:07  Hi, I’m 24F. I stay home 24/7 , everyday. I do...   \n",
       "1  2024-03-03 05:40:38  I am learning that affirmations and the like c...   \n",
       "2  2024-03-02 04:33:58  \\ncontent warning for suicide.\\n\\n\\n\\nI dont u...   \n",
       "3  2024-03-04 12:56:01                                    I wanna end me.   \n",
       "4  2024-03-06 15:18:23  If I hug someone I just try my best not to cry...   \n",
       "\n",
       "             subreddit              author media_only  \\\n",
       "0  MentalHealthSupport        Odd-View-667      False   \n",
       "1  MentalHealthSupport     Bananasloog1998      False   \n",
       "2  MentalHealthSupport    penjamincranklin      False   \n",
       "3  MentalHealthSupport   Positive-Parthlow      False   \n",
       "4  MentalHealthSupport  itsRileyigitbanned      False   \n",
       "\n",
       "                                           permalink  num_comments  \\\n",
       "0  /r/MentalHealthSupport/comments/1b3s6ad/i_feel...         154.0   \n",
       "1  /r/MentalHealthSupport/comments/1b59lzz/what_c...          21.0   \n",
       "2  /r/MentalHealthSupport/comments/1b4fkko/what_i...          24.0   \n",
       "3  /r/MentalHealthSupport/comments/1b6a8vz/i_need...          26.0   \n",
       "4  /r/MentalHealthSupport/comments/1b8299d/what_a...          17.0   \n",
       "\n",
       "      upvotes  downvotes  upvotes/subscribers  \n",
       "0  158.585859   1.585859             0.003425  \n",
       "1   45.454545   0.454545             0.000982  \n",
       "2   47.311828   3.311828             0.001022  \n",
       "3   26.315789   1.315789             0.000568  \n",
       "4   21.649485   0.649485             0.000468  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mental_health_support_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0926b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>media_only</th>\n",
       "      <th>permalink</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>downvotes</th>\n",
       "      <th>upvotes/subscribers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My daughter is scaring me tonight. No idea how...</td>\n",
       "      <td>924</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2023-12-09 02:50:29</td>\n",
       "      <td>My daughter (10) very suddenly this evening sa...</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>ajgl1990</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/mentalhealth/comments/18e3pnh/my_daughter_i...</td>\n",
       "      <td>246</td>\n",
       "      <td>942.857143</td>\n",
       "      <td>18.857143</td>\n",
       "      <td>0.002010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brain cancer at 16… I’m a mess now.</td>\n",
       "      <td>830</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2023-11-10 22:18:46</td>\n",
       "      <td>Became extremely I’ll at 16 and told my mom “t...</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>Intelligent_Pipe7980</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/mentalhealth/comments/17sfgi8/brain_cancer_...</td>\n",
       "      <td>88</td>\n",
       "      <td>846.938776</td>\n",
       "      <td>16.938776</td>\n",
       "      <td>0.001806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I did it. I graduated. I didn’t let depression...</td>\n",
       "      <td>822</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2023-06-14 15:15:05</td>\n",
       "      <td>Depression took over but I won.</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>No_Panic2551</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/mentalhealth/comments/149ah8y/i_did_it_i_gr...</td>\n",
       "      <td>137</td>\n",
       "      <td>830.303030</td>\n",
       "      <td>8.303030</td>\n",
       "      <td>0.001770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Date raped and now pregnant and I’m just so sad</td>\n",
       "      <td>727</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2023-11-25 04:06:49</td>\n",
       "      <td>I’ve never been to therapy despite a bunch of ...</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>Sensitive_World7780</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/mentalhealth/comments/183b3u5/date_raped_an...</td>\n",
       "      <td>61</td>\n",
       "      <td>773.404255</td>\n",
       "      <td>46.404255</td>\n",
       "      <td>0.001649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I killed myself on Monday and feel like I will...</td>\n",
       "      <td>662</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2023-07-02 12:58:41</td>\n",
       "      <td>I think the title says enough, on Monday I lit...</td>\n",
       "      <td>mentalhealth</td>\n",
       "      <td>Dry_Opportunity8703</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/mentalhealth/comments/14onpo2/i_killed_myse...</td>\n",
       "      <td>127</td>\n",
       "      <td>682.474227</td>\n",
       "      <td>20.474227</td>\n",
       "      <td>0.001455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score  upvote_ratio  \\\n",
       "0  My daughter is scaring me tonight. No idea how...    924          0.98   \n",
       "1                Brain cancer at 16… I’m a mess now.    830          0.98   \n",
       "2  I did it. I graduated. I didn’t let depression...    822          0.99   \n",
       "3    Date raped and now pregnant and I’m just so sad    727          0.94   \n",
       "4  I killed myself on Monday and feel like I will...    662          0.97   \n",
       "\n",
       "           created_utc                                           selftext  \\\n",
       "0  2023-12-09 02:50:29  My daughter (10) very suddenly this evening sa...   \n",
       "1  2023-11-10 22:18:46  Became extremely I’ll at 16 and told my mom “t...   \n",
       "2  2023-06-14 15:15:05                    Depression took over but I won.   \n",
       "3  2023-11-25 04:06:49  I’ve never been to therapy despite a bunch of ...   \n",
       "4  2023-07-02 12:58:41  I think the title says enough, on Monday I lit...   \n",
       "\n",
       "      subreddit                author  media_only  \\\n",
       "0  mentalhealth              ajgl1990       False   \n",
       "1  mentalhealth  Intelligent_Pipe7980       False   \n",
       "2  mentalhealth          No_Panic2551       False   \n",
       "3  mentalhealth   Sensitive_World7780       False   \n",
       "4  mentalhealth   Dry_Opportunity8703       False   \n",
       "\n",
       "                                           permalink  num_comments  \\\n",
       "0  /r/mentalhealth/comments/18e3pnh/my_daughter_i...           246   \n",
       "1  /r/mentalhealth/comments/17sfgi8/brain_cancer_...            88   \n",
       "2  /r/mentalhealth/comments/149ah8y/i_did_it_i_gr...           137   \n",
       "3  /r/mentalhealth/comments/183b3u5/date_raped_an...            61   \n",
       "4  /r/mentalhealth/comments/14onpo2/i_killed_myse...           127   \n",
       "\n",
       "      upvotes  downvotes  upvotes/subscribers  \n",
       "0  942.857143  18.857143             0.002010  \n",
       "1  846.938776  16.938776             0.001806  \n",
       "2  830.303030   8.303030             0.001770  \n",
       "3  773.404255  46.404255             0.001649  \n",
       "4  682.474227  20.474227             0.001455  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mental_health_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eed596",
   "metadata": {},
   "source": [
    "### Text Preprocessing (Tokenization and Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57b75465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization/normalization \n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaf19a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessing to 'selftext'\n",
    "df['tokens'] = df['selftext'].apply(lambda x: preprocess_text(x) if isinstance(x, str) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76cfb9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        return [lemmatizer.lemmatize(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# apply preprocessing to 'selftext' in both df\n",
    "mental_health_support_df['tokens'] = Parallel(n_jobs=-1)(delayed(preprocess_text)(text) for text in mental_health_support_df['selftext'])\n",
    "mental_health_df['tokens'] = Parallel(n_jobs=-1)(delayed(preprocess_text)(text) for text in mental_health_df['selftext'])\n",
    "\n",
    "# function for analyzing subreddits\n",
    "def analyze_subreddit(subreddit_df):\n",
    "    numerical_stats = subreddit_df.describe()\n",
    "    token_count_stats = subreddit_df['tokens'].apply(len).describe()\n",
    "    all_tokens = [token for tokens in subreddit_df['tokens'] for token in tokens]\n",
    "    most_common_words = Counter(all_tokens).most_common(10)\n",
    "    return numerical_stats, token_count_stats, most_common_words\n",
    "\n",
    "# sentiment analysis functions\n",
    "def get_sentiment_category(sentiment):\n",
    "    if sentiment['compound'] > 0:\n",
    "        return 'positive'\n",
    "    elif sentiment['compound'] < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "def analyze_sentiments(subreddit_df):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    subreddit_df['sentiment'] = subreddit_df['selftext'].apply(lambda x: sid.polarity_scores(x) if isinstance(x, str) else {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0})\n",
    "    subreddit_df['sentiment_category'] = subreddit_df['sentiment'].apply(get_sentiment_category)\n",
    "    sentiment_stats = subreddit_df['sentiment'].apply(lambda x: x['compound']).describe()\n",
    "    sentiment_category_counts = subreddit_df['sentiment_category'].value_counts()\n",
    "    return sentiment_stats, sentiment_category_counts\n",
    "\n",
    "# function to generate word cloud\n",
    "def generate_word_cloud(tokens, title):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(tokens))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# topic modeling function\n",
    "def topic_modeling(tokens_list, num_topics=5):\n",
    "    dictionary = corpora.Dictionary(tokens_list)\n",
    "    corpus = [dictionary.doc2bow(tokens) for tokens in tokens_list]\n",
    "    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
    "    topics = lda_model.print_topics(num_words=10)\n",
    "    return topics\n",
    "\n",
    "# time series plot function\n",
    "def plot_time_series(subreddit_df, title):\n",
    "    subreddit_df['created_utc'] = pd.to_datetime(subreddit_df['created_utc'], unit='s')\n",
    "    subreddit_df.set_index('created_utc', inplace=True)\n",
    "    monthly_counts = subreddit_df.resample('M').size()\n",
    "    monthly_counts.plot(figsize=(10, 5), title=title)\n",
    "    plt.ylabel('Number of Posts')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d7a2d",
   "metadata": {},
   "source": [
    "## Descriptive Statistics \n",
    "\n",
    "### r/MentalHealthSupport subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69d7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r/MentalHealthSupport subreddit\n",
    "mental_health_support_numerical_stats, mental_health_support_token_count_stats, mental_health_support_common_words = analyze_subreddit(mental_health_support_df)\n",
    "mental_health_support_sentiment_stats, mental_health_support_sentiment_category_counts = analyze_sentiments(mental_health_support_df)\n",
    "mental_health_support_topics = topic_modeling(mental_health_support_df['tokens'].tolist())\n",
    "\n",
    "# word cloud for r/MentalHealthSupport subreddit\n",
    "positive_words = [token for tokens, sentiment in zip(mental_health_support_df['tokens'], mental_health_support_df['sentiment_category']) if sentiment == 'positive' for token in tokens]\n",
    "neutral_words = [token for tokens, sentiment in zip(mental_health_support_df['tokens'], mental_health_support_df['sentiment_category']) if sentiment == 'neutral' for token in tokens]\n",
    "negative_words = [token for tokens, sentiment in zip(mental_health_support_df['tokens'], mental_health_support_df['sentiment_category']) if sentiment == 'negative' for token in tokens]\n",
    "\n",
    "generate_word_cloud(positive_words, \"Positive Words in r/MentalHealthSupport\")\n",
    "generate_word_cloud(neutral_words, \"Neutral Words in r/MentalHealthSupport\")\n",
    "generate_word_cloud(negative_words, \"Negative Words in r/MentalHealthSupport\")\n",
    "\n",
    "# time series analysis for r/MentalHealthSupport subreddit\n",
    "#plot_time_series(mental_health_support_df, \"Posts Over Time in r/MentalHealthSupport\")\n",
    "\n",
    "# statistics for r/MentalHealthSupport subreddit\n",
    "print(\"\\nDescriptive Statistics for r/MentalHealthSupport:\")\n",
    "print(\"Numerical Statistics:\\n\", mental_health_support_numerical_stats)\n",
    "print(\"\\nToken Count Statistics:\\n\", mental_health_support_token_count_stats)\n",
    "print(\"\\nMost Common Words:\\n\", mental_health_support_common_words)\n",
    "print(\"\\nSentiment Statistics:\\n\", mental_health_support_sentiment_stats)\n",
    "print(\"\\nSentiment Category Counts:\\n\", mental_health_support_sentiment_category_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a411667b",
   "metadata": {},
   "source": [
    "### r/MentalHealth subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c7e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r/MentalHealth subreddit\n",
    "mental_health_numerical_stats, mental_health_token_count_stats, mental_health_common_words = analyze_subreddit(mental_health_df)\n",
    "mental_health_sentiment_stats, mental_health_sentiment_category_counts = analyze_sentiments(mental_health_df)\n",
    "mental_health_topics = topic_modeling(mental_health_df['tokens'].tolist())\n",
    "\n",
    "# word cloud for r/MentalHealth subreddit\n",
    "positive_words = [token for tokens, sentiment in zip(mental_health_df['tokens'], mental_health_df['sentiment_category']) if sentiment == 'positive' for token in tokens]\n",
    "neutral_words = [token for tokens, sentiment in zip(mental_health_df['tokens'], mental_health_df['sentiment_category']) if sentiment == 'neutral' for token in tokens]\n",
    "negative_words = [token for tokens, sentiment in zip(mental_health_df['tokens'], mental_health_df['sentiment_category']) if sentiment == 'negative' for token in tokens]\n",
    "\n",
    "generate_word_cloud(positive_words, \"Positive Words in r/MentalHealth\")\n",
    "generate_word_cloud(neutral_words, \"Neutral Words in r/MentalHealth\")\n",
    "generate_word_cloud(negative_words, \"Negative Words in r/MentalHealth\")\n",
    "\n",
    "# time series analysis for r/MentalHealth subreddit\n",
    "plot_time_series(mental_health_df, \"Posts Over Time in r/MentalHealth\")\n",
    "\n",
    "# print statistics for r/MentalHealth subreddit\n",
    "print(\"\\nDescriptive Statistics for r/MentalHealth:\")\n",
    "print(\"Numerical Statistics:\\n\", mental_health_numerical_stats)\n",
    "print(\"\\nToken Count Statistics:\\n\", mental_health_token_count_stats)\n",
    "print(\"\\nMost Common Words:\\n\", mental_health_common_words)\n",
    "print(\"\\nSentiment Statistics:\\n\", mental_health_sentiment_stats)\n",
    "print(\"\\nSentiment Category Counts:\\n\", mental_health_sentiment_category_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4126db44",
   "metadata": {},
   "source": [
    "### combined subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a80fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine both df into one\n",
    "mental_health_support_df.reset_index(inplace=True)\n",
    "mental_health_df.reset_index(inplace=True)\n",
    "\n",
    "df = pd.concat([mental_health_support_df, \n",
    "                mental_health_df], \n",
    "               ignore_index=True)\n",
    "\n",
    "# save processed dataframes to CSV files\n",
    "df.to_csv('data/reddit_posts_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined subreddit\n",
    "df_numerical_stats, df_token_count_stats, df_common_words = analyze_subreddit(df)\n",
    "df_sentiment_stats, df_sentiment_category_counts = analyze_sentiments(df)\n",
    "df_topics = topic_modeling(df['tokens'].tolist())\n",
    "\n",
    "# word cloud for r/MentalHealth subreddit\n",
    "positive_words = [token for tokens, sentiment in zip(df['tokens'], df['sentiment_category']) if sentiment == 'positive' for token in tokens]\n",
    "neutral_words = [token for tokens, sentiment in zip(df['tokens'], df['sentiment_category']) if sentiment == 'neutral' for token in tokens]\n",
    "negative_words = [token for tokens, sentiment in zip(df['tokens'],df['sentiment_category']) if sentiment == 'negative' for token in tokens]\n",
    "\n",
    "generate_word_cloud(positive_words, \"Positive Words in combined subreddit\")\n",
    "generate_word_cloud(neutral_words, \"Neutral Words in combined subreddit\")\n",
    "generate_word_cloud(negative_words, \"Negative Words in combined subreddit\")\n",
    "\n",
    "# time series analysis for combined subreddit\n",
    "plot_time_series(df, \"Posts Over Time in r/MentalHealth\")\n",
    "\n",
    "# print statistics for r/MentalHealth subreddit\n",
    "print(\"\\nDescriptive Statistics for combined subreddit:\")\n",
    "print(\"Numerical Statistics:\\n\", df_numerical_stats)\n",
    "print(\"\\nToken Count Statistics:\\n\", df_token_count_stats)\n",
    "print(\"\\nMost Common Words:\\n\", df_common_words)\n",
    "print(\"\\nSentiment Statistics:\\n\", df_sentiment_stats)\n",
    "print(\"\\nSentiment Category Counts:\\n\", df_sentiment_category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df354a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed dataframes to CSV files\n",
    "mental_health_support_df.to_csv('data/mental_health_support_cleaned.csv', index=False)\n",
    "mental_health_df.to_csv('data/mental_health_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09442601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization/normalization \n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ed1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessing to 'selftext'\n",
    "df['tokens'] = df['selftext'].apply(lambda x: preprocess_text(x) if isinstance(x, str) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397adaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptive statistics\n",
    "numerical_stats = df.describe()\n",
    "token_count_stats = df['tokens'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common words\n",
    "all_tokens = [token for tokens in df['tokens'] for token in tokens]\n",
    "fdist = FreqDist(all_tokens)\n",
    "most_common_words = fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5429f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output statistics\n",
    "print(\"Numerical Statistics:\\n\", numerical_stats)\n",
    "print(\"\\nToken Count Statistics:\\n\", token_count_stats)\n",
    "print(\"\\nMost Common Words:\\n\", most_common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ae513",
   "metadata": {},
   "source": [
    "The descriptive statistics were reviewed separately for each subreddit (r/MentalHealth and r/MentalHealthSupport) rather than in a combined manner. By focusing individually on each subreddit, we can gain deeper insights into specific trends within each subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b85d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviwing as seperate df \n",
    "mental_health_support_df = pd.read_csv('data/mental_health_support_posts.csv')\n",
    "mental_health_df = pd.read_csv('data/mental_health_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# removing additional stop words\n",
    "#additional_stopwords = {'like', 'feel', 'know', 'get', 'time', 'want', 'life', 'even', 'thing', 'year'}\n",
    "#stop_words = stop_words.union(additional_stopwords)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "def analyze_subreddit(subreddit_df):\n",
    "    subreddit_df['tokens'] = subreddit_df['selftext'].apply(lambda x: preprocess_text(x) if isinstance(x, str) else [])\n",
    "    numerical_stats = subreddit_df.describe()\n",
    "    token_count_stats = subreddit_df['tokens'].apply(len).describe()\n",
    "    all_tokens = [token for tokens in subreddit_df['tokens'] for token in tokens]\n",
    "    fdist = FreqDist(all_tokens)\n",
    "    most_common_words = fdist.most_common(10)\n",
    "    return numerical_stats, token_count_stats, most_common_words\n",
    "\n",
    "def analyze_sentiments(subreddit_df):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def get_sentiment_category(sentiment):\n",
    "        if sentiment['compound'] > 0:\n",
    "            return 'positive'\n",
    "        elif sentiment['compound'] < 0:\n",
    "            return 'negative'\n",
    "        else:\n",
    "            return 'neutral'\n",
    "    \n",
    "    # Perform sentiment analysis and store results in new columns\n",
    "    subreddit_df['sentiment'] = subreddit_df['selftext'].apply(lambda x: sid.polarity_scores(x) if isinstance(x, str) else {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0})\n",
    "    \n",
    "    subreddit_df['sentiment_category'] = subreddit_df['sentiment'].apply(get_sentiment_category)\n",
    "    \n",
    "    # Extract compound score for description\n",
    "    sentiment_stats = subreddit_df['sentiment'].apply(lambda x: x['compound']).describe()\n",
    "    \n",
    "    # Count sentiment categories\n",
    "    sentiment_category_counts = subreddit_df['sentiment_category'].value_counts()\n",
    "    \n",
    "    return sentiment_stats, sentiment_category_counts\n",
    "\n",
    "def analyze_sentiments_vader(texts):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiments = []\n",
    "    for text in texts:\n",
    "        if isinstance(text, str):\n",
    "            sentiment = sid.polarity_scores(text)\n",
    "        else:\n",
    "            sentiment = sid.polarity_scores('')\n",
    "        sentiments.append(sentiment)\n",
    "    return sentiments\n",
    "\n",
    "def generate_word_cloud(tokens, title):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(tokens))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def topic_modeling(tokens_list, num_topics=5):\n",
    "    dictionary = corpora.Dictionary(tokens_list)\n",
    "    corpus = [dictionary.doc2bow(tokens) for tokens in tokens_list]\n",
    "    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
    "    topics = lda_model.print_topics(num_words=10)\n",
    "    return topics\n",
    "\n",
    "def plot_time_series(subreddit_df, title):\n",
    "    subreddit_df.set_index('created_utc', inplace=True)\n",
    "    monthly_counts = subreddit_df.resample('M').size()\n",
    "    monthly_counts.plot(figsize=(10, 5), title=title)\n",
    "    plt.ylabel('Number of Posts')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faee4f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics for r/MentalHealthSupport:\n",
      "Numerical Statistics:\n",
      "        num_comments      upvotes    downvotes  upvotes/subscribers\n",
      "count   1921.000000  1921.000000  1921.000000          1921.000000\n",
      "mean       2.138470     2.940360     0.131406             0.000064\n",
      "std        5.325898     4.912228     0.355495             0.000106\n",
      "min        0.000000     0.000000     0.000000             0.000000\n",
      "25%        0.000000     1.000000     0.000000             0.000022\n",
      "50%        0.000000     2.000000     0.000000             0.000043\n",
      "75%        2.000000     3.000000     0.000000             0.000065\n",
      "max      154.000000   160.606061     3.462366             0.003469\n",
      "\n",
      "Token Count Statistics:\n",
      " count    1923.000000\n",
      "mean      113.549662\n",
      "std       115.038961\n",
      "min         0.000000\n",
      "25%        42.000000\n",
      "50%        80.000000\n",
      "75%       142.000000\n",
      "max      1146.000000\n",
      "Name: tokens, dtype: float64\n",
      "\n",
      "Most Common Words:\n",
      " [('like', 3619), ('feel', 3317), ('know', 2269), ('time', 1903), ('get', 1883), ('want', 1814), ('life', 1708), ('even', 1600), ('thing', 1583), ('really', 1489)]\n",
      "\n",
      "Sentiment Statistics:\n",
      " count    1923.000000\n",
      "mean       -0.222940\n",
      "std         0.795554\n",
      "min        -0.999800\n",
      "25%        -0.957550\n",
      "50%        -0.637500\n",
      "75%         0.710200\n",
      "max         0.999700\n",
      "Name: sentiment, dtype: float64\n",
      "\n",
      "Sentiment Category Counts:\n",
      " negative    1183\n",
      "positive     723\n",
      "neutral       17\n",
      "Name: sentiment_category, dtype: int64\n",
      "\n",
      "Sampled Positive Words:\n",
      "['insurance', 'new', 'current', 'online', 'way', 'since', 'something', 'loved', 'people', 'mental', 'outweighs', 'always', 'time', 'respond', 'show', 'seeing', 'severly', 'way', 'men', 'post']\n",
      "\n",
      "Sampled Neutral Words:\n",
      "['never', 'anyone', 'due', 'trying', 'see', 'past', 'im', 'frequent', 'heavy', 'gotten', 'na', 'built', 'content', 'follow', 'stop', 'people', 'least', 'sleep', 'life', 'gaslight']\n",
      "\n",
      "Sampled Negative Words:\n",
      "['nowhere', 'pulling', 'time', 'shape', 'meet', 'want', 'nutrition', 'start', 'ashamed', 'sob', 'posting', 'wind', 'pregnant', 'maintain', 'ashamed', 'held', 'mess', 'cope', 'partner', 'page']\n"
     ]
    }
   ],
   "source": [
    "#'r/MentalHealthSupport' subreddit\n",
    "mental_health_support_numerical_stats, mental_health_support_token_count_stats, mental_health_support_common_words = analyze_subreddit(mental_health_support_df)\n",
    "mental_health_support_sentiment_stats, mental_health_support_sentiment_category_counts = analyze_sentiments(mental_health_support_df)\n",
    "mental_health_support_topics = topic_modeling(mental_health_support_df['tokens'].tolist())\n",
    "\n",
    "# extract words\n",
    "sample_size = 20  \n",
    "\n",
    "positive_words = [token for tokens, sentiment in zip(mental_health_support_df['tokens'], mental_health_support_df['sentiment_category']) if sentiment == 'positive' for token in tokens]\n",
    "neutral_words = [token for tokens, sentiment in zip(mental_health_support_df['tokens'], mental_health_support_df['sentiment_category']) if sentiment == 'neutral' for token in tokens]\n",
    "negative_words = [token for tokens, sentiment in zip(mental_health_support_df['tokens'], mental_health_support_df['sentiment_category']) if sentiment == 'negative' for token in tokens]\n",
    "\n",
    "positive_sample = random.sample(positive_words, min(len(positive_words), sample_size))\n",
    "neutral_sample = random.sample(neutral_words, min(len(neutral_words), sample_size))\n",
    "negative_sample = random.sample(negative_words, min(len(negative_words), sample_size))\n",
    "\n",
    "\n",
    "print(\"\\nDescriptive Statistics for r/MentalHealthSupport:\")\n",
    "print(\"Numerical Statistics:\\n\", mental_health_support_numerical_stats)\n",
    "print(\"\\nToken Count Statistics:\\n\", mental_health_support_token_count_stats)\n",
    "print(\"\\nMost Common Words:\\n\", mental_health_support_common_words)\n",
    "print(\"\\nSentiment Statistics:\\n\", mental_health_support_sentiment_stats)\n",
    "print(\"\\nSentiment Category Counts:\\n\", mental_health_support_sentiment_category_counts)\n",
    "\n",
    "\n",
    "print(\"\\nSampled Positive Words:\")\n",
    "print(positive_sample)\n",
    "\n",
    "print(\"\\nSampled Neutral Words:\")\n",
    "print(neutral_sample)\n",
    "\n",
    "print(\"\\nSampled Negative Words:\")\n",
    "print(negative_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3117df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics for r/MentalHealth:\n",
      "Numerical Statistics:\n",
      "              score  upvote_ratio  num_comments      upvotes    downvotes  \\\n",
      "count  2042.000000   2042.000000   2042.000000  2042.000000  2042.000000   \n",
      "mean     55.695397      0.952870     31.820274    58.495695     2.800298   \n",
      "std      93.493854      0.091493     56.339860    97.387250     6.375583   \n",
      "min       0.000000      0.280000      0.000000     0.000000     0.000000   \n",
      "25%       1.000000      0.950000      1.000000     1.000000     0.000000   \n",
      "50%      11.000000      0.990000      8.000000    11.978261     0.492537   \n",
      "75%      69.750000      1.000000     42.000000    72.979167     2.678106   \n",
      "max     930.000000      1.000000    616.000000   948.979592    61.769231   \n",
      "\n",
      "       upvotes/subscribers  \n",
      "count          2042.000000  \n",
      "mean              0.000125  \n",
      "std               0.000208  \n",
      "min               0.000000  \n",
      "25%               0.000002  \n",
      "50%               0.000026  \n",
      "75%               0.000156  \n",
      "max               0.002023  \n",
      "\n",
      "Token Count Statistics:\n",
      " count    2042.000000\n",
      "mean       79.175808\n",
      "std        70.618524\n",
      "min         0.000000\n",
      "25%        31.000000\n",
      "50%        62.000000\n",
      "75%       104.750000\n",
      "max       939.000000\n",
      "Name: tokens, dtype: float64\n",
      "\n",
      "Most Common Words:\n",
      " [('like', 2779), ('feel', 2551), ('know', 1696), ('time', 1412), ('want', 1371), ('get', 1350), ('life', 1278), ('even', 1193), ('thing', 1124), ('people', 1112)]\n",
      "\n",
      "Sentiment Statistics:\n",
      " count    2042.000000\n",
      "mean       -0.153922\n",
      "std         0.771857\n",
      "min        -0.999100\n",
      "25%        -0.916900\n",
      "50%        -0.426100\n",
      "75%         0.718500\n",
      "max         0.998500\n",
      "Name: sentiment, dtype: float64\n",
      "\n",
      "Sentiment Category Counts:\n",
      " negative    1168\n",
      "positive     826\n",
      "neutral       48\n",
      "Name: sentiment_category, dtype: int64\n",
      "\n",
      "Sampled Positive Words:\n",
      "['point', 'time', 'write', 'open', 'treat', 'know', 'friend', 'know', 'month', 'material', 'trying', 'knew', 'without', 'advice', 'moved', 'exercising', 'one', 'answer', 'friend', 'curious']\n",
      "\n",
      "Sampled Neutral Words:\n",
      "['work', 'prioritize', 'still', 'question', 'fact', 'guess', 'place', 'others', 'person', 'real', 'life', 'country', 'people', 'joyscrolling', 'female', 'doomscrolling', 'dont', 'girl', 'straightforward', 'pregnancy']\n",
      "\n",
      "Sampled Negative Words:\n",
      "['first', 'far', 'shared', 'sick', 'asylum', 'tw', 'decided', 'someone', 'gave', 'throw', 'attempted', 'feeling', 'around', 'mom', 'literally', 'institutionalized', 'person', 'discussed', 'influence', 'would']\n"
     ]
    }
   ],
   "source": [
    "#'r/MentalHealth' subreddit\n",
    "mental_health_numerical_stats, mental_health_token_count_stats, mental_health_common_words = analyze_subreddit(mental_health_df)\n",
    "mental_health_sentiment_stats, mental_health_sentiment_category_counts = analyze_sentiments(mental_health_df)\n",
    "mental_health_topics = topic_modeling(mental_health_df['tokens'].tolist())\n",
    "\n",
    "# extract words\n",
    "sample_size = 20  \n",
    "\n",
    "positive_words = [token for tokens, sentiment in zip(mental_health_df['tokens'], mental_health_df['sentiment_category']) if sentiment == 'positive' for token in tokens]\n",
    "neutral_words = [token for tokens, sentiment in zip(mental_health_df['tokens'], mental_health_df['sentiment_category']) if sentiment == 'neutral' for token in tokens]\n",
    "negative_words = [token for tokens, sentiment in zip(mental_health_df['tokens'], mental_health_df['sentiment_category']) if sentiment == 'negative' for token in tokens]\n",
    "\n",
    "positive_sample = random.sample(positive_words, min(len(positive_words), sample_size))\n",
    "neutral_sample = random.sample(neutral_words, min(len(neutral_words), sample_size))\n",
    "negative_sample = random.sample(negative_words, min(len(negative_words), sample_size))\n",
    "\n",
    "print(\"\\nDescriptive Statistics for r/MentalHealth:\")\n",
    "print(\"Numerical Statistics:\\n\", mental_health_numerical_stats)\n",
    "print(\"\\nToken Count Statistics:\\n\", mental_health_token_count_stats)\n",
    "print(\"\\nMost Common Words:\\n\", mental_health_common_words)\n",
    "print(\"\\nSentiment Statistics:\\n\", mental_health_sentiment_stats)\n",
    "print(\"\\nSentiment Category Counts:\\n\", mental_health_sentiment_category_counts)\n",
    "\n",
    "print(\"\\nSampled Positive Words:\")\n",
    "print(positive_sample)\n",
    "\n",
    "print(\"\\nSampled Neutral Words:\")\n",
    "print(neutral_sample)\n",
    "\n",
    "print(\"\\nSampled Negative Words:\")\n",
    "print(negative_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
